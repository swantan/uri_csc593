{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6\n",
    "\n",
    "*(Due Saturday, October 26, 2019 at noon.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** Below, paste the code needed to import and clean your file from the `../dataset` directory in your repository, then save the result to a new file. I should be able to run the code in this notebook and get my own copy of your cleaned, processed data.\n",
    "\n",
    "**Note:** Your assignment file will be publicly accessible on Github. If your dataset is private, don't print anything confidential in this assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Resident Status',\n",
       " 'Place of Death',\n",
       " 'Data Year',\n",
       " 'Month of Death',\n",
       " 'Sex',\n",
       " 'Race',\n",
       " 'Age',\n",
       " 'Marital Status',\n",
       " 'Education1',\n",
       " '113 Cause Recode',\n",
       " 'Place of Injury',\n",
       " 'Injury at Work',\n",
       " 'Method of Disposition',\n",
       " 'Autopsy']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob as g\n",
    "import re\n",
    "\n",
    "#read in raw data\n",
    "mortality_data_2017 = pd.read_fwf('../my_dataset/US_2017MortalityData', colspecs=((19,20),(82,83),(101,105),(64,66),(68,69),(444,446),(76,78),(83,84),(60,62),(153,156),(144,145),(105,106),(107,108),(108,109)), \n",
    "                  names=['Resident Status', 'Place of Death', 'Data Year', 'Month of Death', 'Sex', 'Race', 'Age', 'Marital Status', 'Education1', '113 Cause Recode', 'Place of Injury', 'Injury at Work', 'Method of Disposition', 'Autopsy'])\n",
    "\n",
    "colnames = list(mortality_data_2017.columns)\n",
    "colnames[5]\n",
    "\n",
    "mortality_data_2017.head()\n",
    "\n",
    "#to subset [row,col]\n",
    "#mortality_data_2017.iloc[990:1000]\n",
    "colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in additional info files\n",
    "\n",
    "#create loop to read in files with the same extension\n",
    "ref_files_list = sorted(g.glob('../my_dataset/ref_touse/*.csv'))\n",
    "\n",
    "#len(ref_files_list)\n",
    "\n",
    "ref_files_list\n",
    "\n",
    "ref_name = [\"resident_status\", \"injury_at_work\", \"method_of_disposition\", \"autopsy\", \"place_of_death\", \n",
    "            \"month_of_death\", \"race_info\", \"age_info\", \"marital_status\", \"education_info1\", \n",
    "            \"cause_code_113\", \"place_of_injury\"]\n",
    "\n",
    "\n",
    "for f in range(len(ref_files_list)):\n",
    "        data_temp = pd.read_csv(ref_files_list[f])\n",
    "        ref_name[f] = data_temp\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_name[5]\n",
    "\n",
    "len(ref_files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = ''\n",
    "#dscols = list(dataset.columns)\n",
    "#files = []\n",
    "#columns = []\n",
    "#for fn in filenames_list:\n",
    "#    newfile = pd.read_csv(fn)\n",
    "#    newfcols = list(newfile.columns)\n",
    "#    inters = set(dscols).intersection(newfcols)\n",
    "    \n",
    "#    pd.merge(dataset, newfile, on = inters)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create loop to read in files with the same extension\n",
    "ref_files_list = sorted(g.glob('../my_dataset/ref_touse/*.csv'))\n",
    "\n",
    "ref_files_list\n",
    "\n",
    "files = []\n",
    "for f in ref_files_list:\n",
    "        file_f_col = list(pd.read_csv(ref_files_list[f]))\n",
    "\n",
    "file_main_col = colnames\n",
    "file1col = list(pd.read_csv('../my_dataset/ref_touse/1. resident_status.csv'))\n",
    "file2col = list(pd.read_csv('../my_dataset/ref_touse/2. place_of_death.csv'))\n",
    "file3col = list(pd.read_csv('../my_dataset/ref_touse/3. month_of_death.csv'))\n",
    "file4col = list(pd.read_csv('../my_dataset/ref_touse/4. race_info.csv'))\n",
    "file5col = list(pd.read_csv('../my_dataset/ref_touse/5. age_info.csv'))\n",
    "file6col = list(pd.read_csv('../my_dataset/ref_touse/6. marital_status.csv'))\n",
    "file7col = list(pd.read_csv('../my_dataset/ref_touse/7. education_info1.csv'))\n",
    "file8col = list(pd.read_csv('../my_dataset/ref_touse/8. 113_cause_recode.csv'))\n",
    "file9col = list(pd.read_csv('../my_dataset/ref_touse/9. place_of_injury.csv'))\n",
    "file10col = list(pd.read_csv('../my_dataset/ref_touse/10. injury_at_work.csv'))\n",
    "file11col = list(pd.read_csv('../my_dataset/ref_touse/11. method_of_disposition.csv'))\n",
    "file12col = list(pd.read_csv('../my_dataset/ref_touse/12. autopsy.csv'))\n",
    "\n",
    "\n",
    "set(file_main_col).intersection(file1col)\n",
    "ref_files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge_temp = \"\"\n",
    "#for f in range(len(ref_files_list)):\n",
    "#        merge_temp = pd.merge(mortality_data_2017, ref_name[f], on = )\n",
    "#        ref_name[f] = merge_temp\n",
    "#not sure how to loop through to merge files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually merge\n",
    "mortdata2017_1 = pd.merge(mortality_data_2017, ref_name[0],  on=['Resident Status'])\n",
    "mortdata2017_2 = pd.merge(mortdata2017_1, ref_name[4],  on=['Place of Death'])\n",
    "mortdata2017_3 = pd.merge(mortdata2017_2, ref_name[5],  on=['Month of Death'])\n",
    "mortdata2017_4 = pd.merge(mortdata2017_3, ref_name[6],  on=['Race'])\n",
    "mortdata2017_5 = pd.merge(mortdata2017_4, ref_name[7],  on=['Age'])\n",
    "mortdata2017_6 = pd.merge(mortdata2017_5, ref_name[8],  on=['Marital Status'])\n",
    "mortdata2017_7 = pd.merge(mortdata2017_6, ref_name[9],  on=['Education1'])\n",
    "mortdata2017_8 = pd.merge(mortdata2017_7, ref_name[10],  on=['113 Cause Recode'])\n",
    "mortdata2017_9 = pd.merge(mortdata2017_8, ref_name[11],  on=['Place of Injury'])\n",
    "mortdata2017_10 = pd.merge(mortdata2017_9, ref_name[1],  on=['Injury at Work'])\n",
    "mortdata2017_11 = pd.merge(mortdata2017_10, ref_name[2],  on=['Method of Disposition'])\n",
    "mortdata2017_12 = pd.merge(mortdata2017_11, ref_name[3],  on=['Autopsy'])\n",
    "\n",
    "len(mortdata2017_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mortdata2017_all = mortdata2017_12.dropna()\n",
    "mortdata2017_all.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save your file (change the name if necessary).\n",
    "mortdata2017_all.to_csv('../my_dataset/cleaned_mortalitydata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** A brief survey: Have you taken an introductory statistics course, and if so, do you remember much from it? For example,\n",
    "\n",
    "* Can you articulate the null hypotheses for the questions you formulated last week involving your data? \n",
    "* Do you know what a t-test is for?\n",
    "* Do you know what a *p* value represents?\n",
    "* Do you know what standard deviation is, and how it's calculated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Can you articulate the null hypotheses for the questions you formulated last week involving your data? \n",
    "> not really, still trying to figure it out\n",
    "* Do you know what a t-test is for?\n",
    "> yes, to detect if there are differences in the data, not sure about the details\n",
    "* Do you know what a *p* value represents?\n",
    "> know it as significant value to evaluate if hypotheses formed should be accepted or rejected\n",
    "* Do you know what standard deviation is, and how it's calculated?\n",
    "> sd represents how the data points deviate, can't remember the actual calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting\n",
    "\n",
    "In the Terminal (Mac) or Git Bash (Windows):\n",
    "\n",
    "`git commit -a -m 'Assignment 6 completed'`  \n",
    "`git push`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading\n",
    "\n",
    "1. [_Python for Data Analysis_](https://uri-primo.hosted.exlibrisgroup.com/permalink/f/10nopmq/01URI_ALMA51209454630002396):\n",
    "    * Section 7.3\n",
    "    * Chapter 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
